{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16-825 Assignment 2: Single View to 3D\n",
    "\n",
    "[Mukai (Tom Notch) Yu](https://tomnotch.com)\n",
    "\n",
    "[mukaiy@andrew.cmu.edu](mailto:mukaiy@andrew.cmu.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Fitting a voxel grid (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![voxel](vis/fit_voxel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Fitting a point cloud (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pointcloud](vis/fit_pointcloud.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Fitting a mesh (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mesh](vis/fit_mesh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reconstructing 3D from single view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Image to voxel grid (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vox](vis/0_vox_renderer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vox](vis/200_vox_renderer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vox](vis/400_vox_renderer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![voxel](vis/eval_vox.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TA looked at my code and it was fine, but the loss just won't converge under 0.6, I guess this is just a ill-posed question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Image to point cloud (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![point](vis/500_point_renderer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![point](vis/100_point_renderer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![point](vis/200_point_renderer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![point](vis/eval_point.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Image to mesh (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mesh](vis/500_mesh_renderer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mesh](vis/100_mesh_renderer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mesh](vis/200_mesh_renderer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mesh](vis/eval_mesh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Quantitative comparisons(10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voxel can only get ~ 25 F1, whereas point and mesh can get ~75 F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, I'd say that voxel prediction is a highly ill-posed problem, we try to overfit a low res image to some 32 x 32 x 32 probabilities that is not even in the camera coordinate frame, and we don't care how we connect the network, what is it supposed to learn? Absolute nonsense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is **impossible** for the learned mesh to accurately represent the ground truth if initial shape is not isomorphic to the target shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's yet to see how the point cloud would look like if we apply poisson surface reconstruction, it might be just as bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Analyze effects of hyperparams variations (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I increase the `n_points`, the F1 result gets worse, it goes from ~75 to ~50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is reasonable since supervising more points without further sophisticating the model would simply complicates the underlying function to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![point](vis/500_point_renderer_2000.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![point](vis/100_point_renderer_2000.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![point](vis/200_point_renderer_2000.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![point](vis/eval_point_2000.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Interpret your model (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ideas, we can\n",
    "1. color-code the vertices on the initial and final mesh to visualize correspondence\n",
    "1. color-code the point to visualize height, which is a common practice in pointcloud visualization\n",
    "1. render output of previous layers of voxel net to see what (the heck) is going on (wrong) with the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's simply because we human are creatures that can only percept low-dimension data, on the screen it's 2D + color, interactable then becomes 3D + color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![point](vis/100_point_renderer_height.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can perceive some leg, but most of the structure is still coarse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring other architectures / datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Extended dataset for training (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1451 categories? fine, I'll do it for point net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![point](vis/0_point_renderer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![point](vis/300_point_renderer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](vis/700_point_renderer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![point](vis/eval_point.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merely increasing the categories without upgrading the model architecture won't help, we need to increase depth, width, output_dim of the network and train longer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Parametric network (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't do this but I have a few questions, please answer via email if you can"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'am very skeptical about its ability to learn a shape without data association with ground truth points, there is no correspondence assignment between 2D surface vertex and GT 3D points, how do you guarantee that the surfaces won't collapse to only 1 part of the GT mesh?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it solved by limiting the number of output points from each 2D surface to **# GT points / # 2D surfaces**, and the chamfer loss would account for the coverage problem because it considers precision and recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there could be issues with non-isomorphic shape, say I want to learn a ball with multiple holes inside, which requires multiple surface to express, right? I think it's impossible to just train with 1 2D surface?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
